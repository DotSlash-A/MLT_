{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we are creating a dataset with 1 feature, so it will have 2 parameters. also our dataset will have 100 samples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "w1 = 3\n",
    "w0 = 4\n",
    "n = 100\n",
    "\n",
    "X = 10 * np.random.rand(n,)\n",
    "y = w1 + w0 * X + np.random.randn(n,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,) (20,) (80,) (80,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X,y,test_size=0.20, random_state=42)\n",
    "print(X_test.shape, y_test.shape, X_train.shape,y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "array([9.90024676, 7.35151703, 6.3592974 , 2.72672533, 1.00679635])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([41.52856614, 32.62508916, 27.67290551, 14.16761827,  7.21949731])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## lets visualise the tarining set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style(\"white\")\n",
    "f = plt.figure(figsize = (8,8))\n",
    "sns.set_context(\"notebook\",font_scale = 1.5, rc={\"lines.linewidth\":2.5})\n",
    "\n",
    "plt.plot(X_train,y_train,\"b.\")\n",
    "plt.title(\"Data Points\")\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"x$\",fontsize = 18)\n",
    "plt.ylabel(\"y\",rotation = 0, fontsize = 18)\n",
    "plt.axis([0,10,0,40])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 4.14620222],\n       [1.        , 5.8474548 ],\n       [1.        , 8.31918612],\n       [1.        , 8.89992321],\n       [1.        , 0.45147735],\n       [1.        , 2.85446259],\n       [1.        , 8.04866395],\n       [1.        , 2.8131928 ],\n       [1.        , 4.92246042],\n       [1.        , 9.9860126 ],\n       [1.        , 8.34192709],\n       [1.        , 3.31412455],\n       [1.        , 7.36999906],\n       [1.        , 8.05528366],\n       [1.        , 1.28780587],\n       [1.        , 4.02444733],\n       [1.        , 9.87778752],\n       [1.        , 2.82373441],\n       [1.        , 5.22936852],\n       [1.        , 9.04112046],\n       [1.        , 6.86724725],\n       [1.        , 4.9965672 ],\n       [1.        , 6.03100449],\n       [1.        , 6.91834522],\n       [1.        , 0.18571774],\n       [1.        , 8.91429926],\n       [1.        , 6.3592974 ],\n       [1.        , 8.05340126],\n       [1.        , 8.9460463 ],\n       [1.        , 2.20367032],\n       [1.        , 1.62465409],\n       [1.        , 3.47467792],\n       [1.        , 0.71407662],\n       [1.        , 7.2527497 ],\n       [1.        , 4.38599226],\n       [1.        , 2.20495953],\n       [1.        , 4.49657694],\n       [1.        , 9.18883168],\n       [1.        , 4.51630091],\n       [1.        , 5.08351603],\n       [1.        , 5.64973019],\n       [1.        , 4.27509039],\n       [1.        , 2.72672533],\n       [1.        , 4.58542114],\n       [1.        , 3.63485019],\n       [1.        , 7.4156297 ],\n       [1.        , 9.01934072],\n       [1.        , 3.02438063],\n       [1.        , 3.42099346],\n       [1.        , 0.90282981],\n       [1.        , 4.79900808],\n       [1.        , 6.64115788],\n       [1.        , 8.27062574],\n       [1.        , 6.58058721],\n       [1.        , 4.9638509 ],\n       [1.        , 9.90024676],\n       [1.        , 6.97761492],\n       [1.        , 4.26470142],\n       [1.        , 1.91589241],\n       [1.        , 3.84143208],\n       [1.        , 1.06319133],\n       [1.        , 9.03245999],\n       [1.        , 3.07922675],\n       [1.        , 0.35060128],\n       [1.        , 0.72019588],\n       [1.        , 2.26175728],\n       [1.        , 9.1747588 ],\n       [1.        , 9.13992186],\n       [1.        , 2.91940613],\n       [1.        , 1.00679635],\n       [1.        , 9.20794666],\n       [1.        , 8.45868004],\n       [1.        , 7.33883193],\n       [1.        , 4.89414107],\n       [1.        , 5.57693843],\n       [1.        , 4.62752208],\n       [1.        , 0.66916919],\n       [1.        , 1.39972664],\n       [1.        , 8.18232127],\n       [1.        , 8.66843927],\n       [1.        , 7.86994756],\n       [1.        , 7.22690562],\n       [1.        , 2.16893366],\n       [1.        , 4.66520024],\n       [1.        , 7.44183491],\n       [1.        , 3.47245782],\n       [1.        , 8.54055173],\n       [1.        , 9.60128099],\n       [1.        , 7.35151703],\n       [1.        , 8.74904268],\n       [1.        , 3.40679206],\n       [1.        , 9.83446207],\n       [1.        , 5.12332856],\n       [1.        , 1.68825261],\n       [1.        , 2.96190149],\n       [1.        , 3.53009392],\n       [1.        , 2.3341942 ],\n       [1.        , 5.61687275],\n       [1.        , 2.72379738],\n       [1.        , 2.29474714]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.column_stack((np.ones(X.shape[0]),X))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def add_dummy_feature(x):\n",
    "    '''adds dummy feature to the dataset\n",
    "     Args:\n",
    "       x: Training dataset\n",
    "     Returns:\n",
    "          Training dataset with an addition of dummy features\n",
    "     '''\n",
    "    #np.ones(x.shape[0]) creates a vector of 1's having the same no.of rows as no.of samples in dataset\n",
    "    return np.column_stack((np.ones(x.shape[0]),x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 1.],\n       [1., 3.],\n       [1., 4.]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_dummy_feature(np.array([1,3,4]))#test case"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C2- Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear regression model uses linear combination of features to obtain output labels.In vectorized form, thi can be written as $y=Xw$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def predict(X,w):\n",
    "    '''Predictioon of output label for a given input\n",
    "        Args:\n",
    "           X: Feature matrix of shape(n,m+1)\n",
    "           w: weight vector of shape(m+1,n)\n",
    "        Returns:\n",
    "            y:Predicted label vector of shape(n,)\n",
    "    '''\n",
    "    #check that feature matrix and weight vector have compactible shapes\n",
    "    assert X.shape[-1]==w.shape[0]\n",
    "\n",
    "    y = X @ w #matrix vec multiplicaiton\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([11., 21.])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing if predict works or not\n",
    "A = np.array([[1,3,2,5],[1,9,4,7]]) #feature matrix\n",
    "r = np.ones(4)\n",
    "l = predict(A,r)\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Demonstrating this model on a synthetic dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Preparing the dataset\n",
    "[w0,w1]=[4,3]\n",
    "n=100\n",
    "x=10*np.random.randn(n,)\n",
    "y = w0+w1*x+np.random.randn(n,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#preprocessing: dummy feature and train test split\n",
    "X_with_dummy = add_dummy_feature(x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_dummy, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.33772797, 0.85193648])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.rand(2,)\n",
    "w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "y_hat = predict(X_train,w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-2.06486021, 15.48038828,  6.81843367,  0.07126363, -9.37997078,\n       -7.83600073,  0.08417556, -4.15645353, -0.83085727, 12.14559501])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-29.75894778, -39.89520004,   1.9226318 ,   7.41756665,\n       -24.95881154, -34.66510236,   5.07819028,  26.53240804,\n        70.57320967,  -0.38847203])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def non_vectorized_predict(X,w):\n",
    "    '''Prediction of output for a given input.\n",
    "    Args:\n",
    "        X: Feature matrix of shape (n, m+1)\n",
    "        w: Weight vector of shape (m+1, n)\n",
    "    Returns:\n",
    "        y: Predicted label vector of shape (n, ).\n",
    "    '''\n",
    "    y = []\n",
    "    for i in range(0,X.shape[0]):\n",
    "        y_hat_i = 0\n",
    "        for j in range(0,X.shape[1]):\n",
    "            y_hat_i += X[i][j]*w[j]\n",
    "        y.append(y_hat_i)\n",
    "    return np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C3 - Loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loss fun is:\n",
    "$$J(w) = \\frac{1}{2}(Xw-y)^t(Xw-y)$$\n",
    " - X is a feature matrix with (m+1) features for n examples along rows\n",
    " - w is a weight vector containing (m+1) weights one for each feature\n",
    " - y is a label matrix containign labels for n examples in a vector of shape(n,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def loss(features, labels, weights):\n",
    "    e = predict(features, weights) - labels # e = predict(X,w)-y\n",
    "    loss = (1/2) * (np.transpose(e) @ e)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "62.5"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([6,11])\n",
    "loss(A,c,r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C4- Optimaization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimization is done with one of the two following methods:\n",
    "- Normal Equaiton method, that sets the partial derivative of the loss function wrt weight vectors to 0 and solves the resulting equation to obtain the weight vector\n",
    "- Gradient descent method, that iteratively adjusts the weight vectir based on the learning rate and the gradient of loss function at the current weight vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normal equation\n",
    "- we make use of `np.linalg.pinv` for calculating the psuedoinverse of the feature matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    '''Estimates parameters of the linear regression model with normal equation\n",
    "    Args:\n",
    "        X: feature matrix for given inputs.\n",
    "        y: Actual label vector\n",
    "\n",
    "    Returns:\n",
    "        Weight vector\n",
    "    '''\n",
    "    return np.linalg.pinv(X) @ y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "array([4.20420783, 3.00274853])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_equation(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient descent\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### calculating the gradient\n",
    "GD is implemented as follows\n",
    "\n",
    "- Randomly initialize  to 0.\n",
    "- Iterate until convergence:\n",
    "    - Calculate partial derivative of loss w.r.t weight vector\n",
    "    - Calculate new values of weights\n",
    "    - Update weights to new values simultaneously\n",
    "\n",
    "We use number of epochs as a convergence criteria in this implementation\n",
    "*partial derivative of loss function is* $$ \\frac{\\partial }{\\partial w} J(w) = X^T(Xw-y)$$\n",
    "The multipication of transpose of feature matrix with the difference of predicted and actual label vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 15., 105.,  50.,  95.])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_gradient(X,y,w): #(feature matrix,label vector, weights)\n",
    "    return np.transpose(X) @ (predict(X,w)-y)\n",
    "\n",
    "g=calculate_gradient(A,c,r)\n",
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weight updates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def update_weights(w, grad, lr):\n",
    "\n",
    "    '''updates the wieights based on the gradient of the loss function.\n",
    "    weight updates are carried out with the following formula:\n",
    "    w_new := w_old - lr * grad\n",
    "\n",
    "    Args:\n",
    "      1. w : wight vector\n",
    "      2. grad: gradient of loss wrt w\n",
    "      3. lr: learning rate\n",
    "\n",
    "    Returns:\n",
    "      Updated Weight Vector\n",
    "    '''\n",
    "    return (w-(lr*grad))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.985, 0.895, 0.95 , 0.905])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "update_weights(r,g,lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def add_dummy_feature(x):\n",
    "    '''adds dummy feature to the dataset\n",
    "     Args:\n",
    "       x: Training dataset\n",
    "     Returns:\n",
    "          Training dataset with an addition of dummy features\n",
    "     '''\n",
    "    #np.ones(x.shape[0]) creates a vector of 1's having the same no.of rows as no.of samples in dataset\n",
    "    return np.column_stack((np.ones(x.shape[0]),x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 1.],\n       [1., 3.],\n       [1., 4.]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_dummy_feature(np.array([1,3,4]))#test case"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C2- Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Linear regression model uses linear combination of features to obtain output labels.In vectorized form, thi can be written as $y=Xw$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def predict(X,w):\n",
    "    '''Predictioon of output label for a given input\n",
    "        Args:\n",
    "           X: Feature matrix of shape(n,m+1)\n",
    "           w: weight vector of shape(m+1,n)\n",
    "        Returns:\n",
    "            y:Predicted label vector of shape(n,)\n",
    "    '''\n",
    "    #check that feature matrix and weight vector have compactible shapes\n",
    "    assert X.shape[-1]==w.shape[0]\n",
    "\n",
    "    y = X @ w #matrix vec multiplicaiton\n",
    "    return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([11., 21.])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing if predict works or not\n",
    "A = np.array([[1,3,2,5],[1,9,4,7]]) #feature matrix\n",
    "r = np.ones(4)\n",
    "l = predict(A,r)\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Demonstrating this model on a synthetic dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#Preparing the dataset\n",
    "[w0,w1]=[4,3]\n",
    "n=100\n",
    "x=10*np.random.randn(n,)\n",
    "y = w0+w1*x+np.random.randn(n,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#preprocessing: dummy feature and train test split\n",
    "X_with_dummy = add_dummy_feature(x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_with_dummy, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.77252048, 0.64183133])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.rand(2,)\n",
    "w"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "y_hat = predict(X_train,w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 3.86823075e+00, -2.63774787e+00, -7.80459476e+00,  5.32795491e+00,\n        4.19767480e-01,  3.97755397e-04,  3.39414489e+00, -9.98914293e+00,\n        9.23834465e-01,  1.20431740e-01])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-43.75531839,   7.82961186, -53.52551733,   9.63159586,\n        30.89075702,  21.5377427 ,  34.81749116,  49.99446831,\n        -3.28115676,   5.2115958 ])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def non_vectorized_predict(X,w):\n",
    "    '''Prediction of output for a given input.\n",
    "    Args:\n",
    "        X: Feature matrix of shape (n, m+1)\n",
    "        w: Weight vector of shape (m+1, n)\n",
    "    Returns:\n",
    "        y: Predicted label vector of shape (n, ).\n",
    "    '''\n",
    "    y = []\n",
    "    for i in range(0,X.shape[0]):\n",
    "        y_hat_i = 0\n",
    "        for j in range(0,X.shape[1]):\n",
    "            y_hat_i += X[i][j]*w[j]\n",
    "        y.append(y_hat_i)\n",
    "    return np.array(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C3 - Loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loss fun is:\n",
    "$$J(w) = \\frac{1}{2}(Xw-y)^t(Xw-y)$$\n",
    " - X is a feature matrix with (m+1) features for n examples along rows\n",
    " - w is a weight vector containing (m+1) weights one for each feature\n",
    " - y is a label matrix containign labels for n examples in a vector of shape(n,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def loss(features, labels, weights):\n",
    "    e = predict(features, weights) - labels # e = predict(X,w)-y\n",
    "    loss = (1/2) * (np.transpose(e) @ e)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "62.5"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([6,11])\n",
    "loss(A,c,r)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C4- Optimaization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Optimization is done with one of the two following methods:\n",
    "- Normal Equaiton method, that sets the partial derivative of the loss function wrt weight vectors to 0 and solves the resulting equation to obtain the weight vector\n",
    "- Gradient descent method, that iteratively adjusts the weight vectir based on the learning rate and the gradient of loss function at the current weight vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normal equation\n",
    "- we make use of `np.linalg.pinv` for calculating the psuedoinverse of the feature matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    '''Estimates parameters of the linear regression model with normal equation\n",
    "    Args:\n",
    "        X: feature matrix for given inputs.\n",
    "        y: Actual label vector\n",
    "\n",
    "    Returns:\n",
    "        Weight vector\n",
    "    '''\n",
    "    return np.linalg.pinv(X) @ y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "array([3.85906791, 2.97850104])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_equation(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient descent\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### calculating the gradient\n",
    "GD is implemented as follows\n",
    "\n",
    "- Randomly initialize  to 0.\n",
    "- Iterate until convergence:\n",
    "    - Calculate partial derivative of loss w.r.t weight vector\n",
    "    - Calculate new values of weights\n",
    "    - Update weights to new values simultaneously\n",
    "\n",
    "We use number of epochs as a convergence criteria in this implementation\n",
    "*partial derivative of loss function is* $$ \\frac{\\partial }{\\partial w} J(w) = X^T(Xw-y)$$\n",
    "The multipication of transpose of feature matrix with the difference of predicted and actual label vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 15., 105.,  50.,  95.])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_gradient(X,y,w): #(feature matrix,label vector, weights)\n",
    "    return np.transpose(X) @ (predict(X,w)-y)\n",
    "\n",
    "g=calculate_gradient(A,c,r)\n",
    "g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Weight updates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def update_weights(w, grad, lr):\n",
    "\n",
    "    '''updates the wieights based on the gradient of the loss function.\n",
    "    weight updates are carried out with the following formula:\n",
    "    w_new := w_old - lr * grad\n",
    "\n",
    "    Args:\n",
    "      1. w : wight vector\n",
    "      2. grad: gradient of loss wrt w\n",
    "      3. lr: learning rate\n",
    "\n",
    "    Returns:\n",
    "      Updated Weight Vector\n",
    "    '''\n",
    "    return (w-(lr*grad))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.985, 0.895, 0.95 , 0.905])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.001\n",
    "update_weights(r,g,lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}